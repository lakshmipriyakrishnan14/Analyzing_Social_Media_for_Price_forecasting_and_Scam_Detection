{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c02dcbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir(\"/Users/aishu/Library/CloudStorage/OneDrive-UniversityofNorthFlorida/Lakshmi's Research/Fall 2023/Datasets\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d69723ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "btc split 2\n",
      "ETH_final_tweet_sentiments_combined.csv\n",
      "BTC_final_tweet_with_features.csv\n",
      ".DS_Store\n",
      "btc split\n",
      "Tweets data on Cryptocurrency.csv\n",
      "bitcoin\n",
      "BTC_final_tweet_sentiments_combined.csv\n",
      "ethereum\n"
     ]
    }
   ],
   "source": [
    "# List all files in the current directory\n",
    "file_names = os.listdir()\n",
    "\n",
    "# Print the list of file names\n",
    "for file_name in file_names:\n",
    "    print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1c717ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197753, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Tweets data on Cryptocurrency.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c786e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'user_name', 'user_location', 'user_description',\n",
       "       'user_created', 'user_followers', 'user_friends', 'user_favourites',\n",
       "       'user_verified', 'date', 'text', 'hashtags', 'tweet_source',\n",
       "       'user_days_on_twitter', 'RiseFall'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6434d622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 2022-12-01 23:59:00\n",
      "Minimum Date: 2022-01-13 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'date' column to datetime if it's not already in datetime format\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Find the maximum and minimum dates\n",
    "max_date = df['date'].max()\n",
    "min_date = df['date'].min()\n",
    "\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41efde53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and remove rows without hashtags\n",
    "df = df[df['hashtags'].notna()]\n",
    "\n",
    "# remove rows with empty hashtag lists (e.g., '[]')\n",
    "df = df[df['hashtags'].str.len() > 2]  # Assuming '[]' has a length of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60afd94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197753, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b3bbefd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0             user_name             user_location  \\\n",
      "2                2      Dr. Crypto Jones               Atlanta, GA   \n",
      "9                9            Crypto Dev                    Canada   \n",
      "11              11            Crypto Bot           New Orleans, LA   \n",
      "12              12            Crypto Dev                    Canada   \n",
      "13              13            Crypto Bot           New Orleans, LA   \n",
      "...            ...                   ...                       ...   \n",
      "197747      197747        Maximilian-Lex    Buenos Aires ARGENTINA   \n",
      "197748      197748         ꧁༒𝕒𝕓𝕦 𝕙𝕒𝕟𝕚𝕗༒꧂         Dhaka Bangladesh    \n",
      "197749      197749            Neon Jesus  planetpunk.crypto send 🪙   \n",
      "197750      197750  LimeWireCrypto {LWC}                    Crypto   \n",
      "197752      197752            Neon Jesus  planetpunk.crypto send 🪙   \n",
      "\n",
      "                                         user_description     user_created  \\\n",
      "2       I am NOT a financial advisor. I AM a cryptocur...  21/03/2021 1:27   \n",
      "9        Crypto Expert | Bitcoin Expert | Price Analaysis  4/12/2012 11:17   \n",
      "11      Market analysis & recaps, scalping leverage ca...  17/12/2021 3:01   \n",
      "12       Crypto Expert | Bitcoin Expert | Price Analaysis  4/12/2012 11:17   \n",
      "13      Market analysis & recaps, scalping leverage ca...  17/12/2021 3:01   \n",
      "...                                                   ...              ...   \n",
      "197747  \"Vive como si fueras a morir mañana; aprende c...  4/01/2021 22:14   \n",
      "197748  💯💯💯 follow back💯💯💯💯💯 💯💯💯💯💯💯❣️❣️❣️🥀🥀🥀follow bac...  7/05/2021 13:37   \n",
      "197749  Project House for Neon Jesus. Follow here for ...  5/11/2021 18:40   \n",
      "197750                                          LWC, KA$H  13/03/2022 8:00   \n",
      "197752  Project House for Neon Jesus. Follow here for ...  5/11/2021 18:40   \n",
      "\n",
      "        user_followers  user_friends  user_favourites  user_verified  \\\n",
      "2                   19           109              132          False   \n",
      "9                  253          1171              132          False   \n",
      "11                  41           175                0          False   \n",
      "12                 253          1171              132          False   \n",
      "13                  41           175                0          False   \n",
      "...                ...           ...              ...            ...   \n",
      "197747            2026          2025            27745           True   \n",
      "197748           20888         22001             3500           True   \n",
      "197749              96           400             2439           True   \n",
      "197750               7            31               68           True   \n",
      "197752              96           400             2439           True   \n",
      "\n",
      "                      date                                               text  \\\n",
      "2      2022-11-01 17:11:00  Not too much, but 2022 be good to me baby! Bin...   \n",
      "9      2022-11-01 17:12:00  @APompliano @QuppyPay Quppy wallet biggest ben...   \n",
      "11     2022-11-01 17:12:00  the strongest bullish signal flashed for #Bitc...   \n",
      "12     2022-11-01 17:12:00  @BitcoinMagazine @RepTomEmmer @QuppyPay Quppy ...   \n",
      "13     2022-11-01 17:12:00  the strongest bullish signal flashed for #Bitc...   \n",
      "...                    ...                                                ...   \n",
      "197747 2022-03-19 23:59:00  If you know what you want, if your goal is cle...   \n",
      "197748 2022-03-19 23:59:00  @TelefyConnect #DeFi #TeleFy #DEX #cryptocurre...   \n",
      "197749 2022-03-19 23:59:00  @nftdreami https://t.co/bODkhxCVE6\\n\\nOnly .06...   \n",
      "197750 2022-03-19 23:59:00  So what i’m seeing and hearing from #Ethereum ...   \n",
      "197752 2022-03-19 23:59:00  @Whiteirons112 https://t.co/bODkhxCVE6\\n\\nOnly...   \n",
      "\n",
      "                                                 hashtags  \\\n",
      "2                          ['nft', 'ethereum', 'bitcoin']   \n",
      "9         ['crypto', 'blockchain', 'bitcoin', 'ethereum']   \n",
      "11      ['bitcoin', 'cryptocurrency', 'metaverse', 'et...   \n",
      "12        ['crypto', 'blockchain', 'bitcoin', 'ethereum']   \n",
      "13      ['bitcoin', 'cryptocurrency', 'metaverse', 'et...   \n",
      "...                                                   ...   \n",
      "197747  ['cryptocurrencies', 'bitcoin', 'ethereum', 'n...   \n",
      "197748  ['defi', 'telefy', 'dex', 'cryptocurrency', 'e...   \n",
      "197749  ['crypto', 'planetpunk', 'nftgiveway', 'freenf...   \n",
      "197750         ['ethereum', 'btc', 'altcoin', 'altcoins']   \n",
      "197752  ['crypto', 'planetpunk', 'nftgiveway', 'freenf...   \n",
      "\n",
      "               tweet_source  user_days_on_twitter RiseFall  \n",
      "2       Twitter for Android                   296    Equal  \n",
      "9           Twitter Web App                  3325    Equal  \n",
      "11      Twitter for Android                    25    Equal  \n",
      "12          Twitter Web App                  3325    Equal  \n",
      "13      Twitter for Android                    25    Equal  \n",
      "...                     ...                   ...      ...  \n",
      "197747      Twitter Web App                   439     Fall  \n",
      "197748  Twitter for Android                   316     Fall  \n",
      "197749      Twitter Web App                   134     Fall  \n",
      "197750   Twitter for iPhone                     6     Fall  \n",
      "197752      Twitter Web App                   134     Fall  \n",
      "\n",
      "[47499 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'hashtags' column to lowercase to perform a case-insensitive search\n",
    "df['hashtags'] = df['hashtags'].str.lower()\n",
    "\n",
    "# Define a list of keywords you want to search for\n",
    "keywords = ['eth', 'ethereum']\n",
    "\n",
    "# Create a regex pattern to match any of the specified keywords\n",
    "pattern = '|'.join(keywords)\n",
    "\n",
    "# Use str.contains() to filter rows with the specified keywords in hashtags\n",
    "filtered_df = df[df['hashtags'].str.contains(pattern, case=False, na=False)]\n",
    "\n",
    "# Print the filtered DataFrame\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a365cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 47499 entries, 2 to 197752\n",
      "Data columns (total 15 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   Unnamed: 0            47499 non-null  int64         \n",
      " 1   user_name             47499 non-null  object        \n",
      " 2   user_location         47499 non-null  object        \n",
      " 3   user_description      47499 non-null  object        \n",
      " 4   user_created          47499 non-null  object        \n",
      " 5   user_followers        47499 non-null  int64         \n",
      " 6   user_friends          47499 non-null  int64         \n",
      " 7   user_favourites       47499 non-null  int64         \n",
      " 8   user_verified         47499 non-null  bool          \n",
      " 9   date                  47499 non-null  datetime64[ns]\n",
      " 10  text                  47499 non-null  object        \n",
      " 11  hashtags              47499 non-null  object        \n",
      " 12  tweet_source          47499 non-null  object        \n",
      " 13  user_days_on_twitter  47499 non-null  int64         \n",
      " 14  RiseFall              47499 non-null  object        \n",
      "dtypes: bool(1), datetime64[ns](1), int64(5), object(8)\n",
      "memory usage: 5.5+ MB\n"
     ]
    }
   ],
   "source": [
    "filtered_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5592b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jd/4dt6h54973j7mc7x_q5d4cwh0000gn/T/ipykernel_18022/3094204154.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=['RiseFall'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "filtered_df.drop(columns=['RiseFall'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "428a4203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 47499 entries, 2 to 197752\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   Unnamed: 0            47499 non-null  int64         \n",
      " 1   user_name             47499 non-null  object        \n",
      " 2   user_location         47499 non-null  object        \n",
      " 3   user_description      47499 non-null  object        \n",
      " 4   user_created          47499 non-null  object        \n",
      " 5   user_followers        47499 non-null  int64         \n",
      " 6   user_friends          47499 non-null  int64         \n",
      " 7   user_favourites       47499 non-null  int64         \n",
      " 8   user_verified         47499 non-null  bool          \n",
      " 9   date                  47499 non-null  datetime64[ns]\n",
      " 10  text                  47499 non-null  object        \n",
      " 11  hashtags              47499 non-null  object        \n",
      " 12  tweet_source          47499 non-null  object        \n",
      " 13  user_days_on_twitter  47499 non-null  int64         \n",
      "dtypes: bool(1), datetime64[ns](1), int64(5), object(7)\n",
      "memory usage: 5.1+ MB\n"
     ]
    }
   ],
   "source": [
    "filtered_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37af2539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jd/4dt6h54973j7mc7x_q5d4cwh0000gn/T/ipykernel_18022/189528385.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=['Unnamed: 0', 'user_name', 'user_description', 'user_followers', 'user_favourites','user_location', 'user_created', 'user_friends', 'user_verified', 'user_days_on_twitter'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "filtered_df.drop(columns=['Unnamed: 0', 'user_name', 'user_description', 'user_followers', 'user_favourites','user_location', 'user_created', 'user_friends', 'user_verified', 'user_days_on_twitter'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f587309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 47499 entries, 2 to 197752\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   date          47499 non-null  datetime64[ns]\n",
      " 1   text          47499 non-null  object        \n",
      " 2   hashtags      47499 non-null  object        \n",
      " 3   tweet_source  47499 non-null  object        \n",
      "dtypes: datetime64[ns](1), object(3)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "filtered_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98415d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/aishu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/aishu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/aishu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "/var/folders/jd/4dt6h54973j7mc7x_q5d4cwh0000gn/T/ipykernel_18022/2225638946.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['processed_text'] = filtered_df['text'].apply(process_text)\n",
      "/var/folders/jd/4dt6h54973j7mc7x_q5d4cwh0000gn/T/ipykernel_18022/2225638946.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['vader_sentiment'] = filtered_df['processed_text'].apply(get_sentiment_vader)\n",
      "/var/folders/jd/4dt6h54973j7mc7x_q5d4cwh0000gn/T/ipykernel_18022/2225638946.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['textblob_sentiment'] = filtered_df['processed_text'].apply(get_sentiment_textblob)\n",
      "/var/folders/jd/4dt6h54973j7mc7x_q5d4cwh0000gn/T/ipykernel_18022/2225638946.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['vader_sentiment_class'] = filtered_df['vader_sentiment'].apply(classify_sentiment_vader)\n",
      "/var/folders/jd/4dt6h54973j7mc7x_q5d4cwh0000gn/T/ipykernel_18022/2225638946.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['textblob_sentiment_class'] = filtered_df['textblob_sentiment'].apply(classify_sentiment_textblob)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize the lemmatizer and get a set of stop words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Initialize the VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to process text\n",
    "def process_text(text):\n",
    "    # Remove special characters using regular expressions\n",
    "    text = re.sub(r'[^A-Za-z0-9]+', ' ', text)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Remove stop words and lemmatize the remaining words\n",
    "    filtered_words = [lemmatizer.lemmatize(word) for word in words if word.lower() not in stop_words]\n",
    "\n",
    "    # Reconstruct the text from the processed words\n",
    "    processed_text = ' '.join(filtered_words)\n",
    "\n",
    "    return processed_text\n",
    "\n",
    "# Apply text processing to the 'text' column\n",
    "filtered_df['processed_text'] = filtered_df['text'].apply(process_text)\n",
    "\n",
    "# Function to get sentiment using VADER\n",
    "def get_sentiment_vader(text):\n",
    "    sentiment = analyzer.polarity_scores(text)\n",
    "    return sentiment['compound']\n",
    "\n",
    "# Function to get sentiment using TextBlob\n",
    "def get_sentiment_textblob(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "# Apply sentiment analysis using VADER\n",
    "filtered_df['vader_sentiment'] = filtered_df['processed_text'].apply(get_sentiment_vader)\n",
    "\n",
    "# Apply sentiment analysis using TextBlob\n",
    "filtered_df['textblob_sentiment'] = filtered_df['processed_text'].apply(get_sentiment_textblob)\n",
    "\n",
    "# Classify sentiment based on compound VADER score\n",
    "def classify_sentiment_vader(compound):\n",
    "    if compound >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif compound <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Classify sentiment based on TextBlob score\n",
    "def classify_sentiment_textblob(score):\n",
    "    if score >= 0.1:\n",
    "        return 'Positive'\n",
    "    elif score <= -0.1:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Apply sentiment classification\n",
    "filtered_df['vader_sentiment_class'] = filtered_df['vader_sentiment'].apply(classify_sentiment_vader)\n",
    "filtered_df['textblob_sentiment_class'] = filtered_df['textblob_sentiment'].apply(classify_sentiment_textblob)\n",
    "\n",
    "# Save the DataFrame with sentiment analysis results\n",
    "filtered_df.to_csv('ETH_final_tweet_sentiments_combined.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d922446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
