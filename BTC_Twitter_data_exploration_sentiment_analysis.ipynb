{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c02dcbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir(\"/Users/aishu/Library/CloudStorage/OneDrive-UniversityofNorthFlorida/Lakshmi's Research/Fall 2023/Datasets\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d69723ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "btc split 2\n",
      "ETH_final_tweet_sentiments_combined.csv\n",
      "BTC_final_tweet_with_features.csv\n",
      ".DS_Store\n",
      "btc split\n",
      "Tweets data on Cryptocurrency.csv\n",
      "bitcoin\n",
      "BTC_final_tweet_sentiments_combined.csv\n",
      "ethereum\n"
     ]
    }
   ],
   "source": [
    "# List all files in the current directory\n",
    "file_names = os.listdir()\n",
    "\n",
    "# Print the list of file names\n",
    "for file_name in file_names:\n",
    "    print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1c717ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197753, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Tweets data on Cryptocurrency.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c786e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'user_name', 'user_location', 'user_description',\n",
       "       'user_created', 'user_followers', 'user_friends', 'user_favourites',\n",
       "       'user_verified', 'date', 'text', 'hashtags', 'tweet_source',\n",
       "       'user_days_on_twitter', 'RiseFall'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6434d622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 2022-12-01 23:59:00\n",
      "Minimum Date: 2022-01-13 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'date' column to datetime if it's not already in datetime format\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Find the maximum and minimum dates\n",
    "max_date = df['date'].max()\n",
    "min_date = df['date'].min()\n",
    "\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41efde53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and remove rows without hashtags\n",
    "df = df[df['hashtags'].notna()]\n",
    "\n",
    "# remove rows with empty hashtag lists (e.g., '[]')\n",
    "df = df[df['hashtags'].str.len() > 2]  # Assuming '[]' has a length of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60afd94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197753, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b3bbefd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0               user_name             user_location  \\\n",
      "0                0  Digital Shogun ·Äïœâ·Äï üõ°üåê‚öî           Rings of Saturn   \n",
      "1                1              Conor Okus                   Global    \n",
      "2                2        Dr. Crypto Jones               Atlanta, GA   \n",
      "3                3       Crypto Rover üßô‚Äç‚ôÇÔ∏è                Bitcoin ü§©üåô   \n",
      "4                4                 Simon üéà             Maryland, USA   \n",
      "...            ...                     ...                       ...   \n",
      "197748      197748           ÍßÅ‡ºíùïíùïìùï¶ ùïôùïíùïüùïöùïó‡ºíÍßÇ         Dhaka Bangladesh    \n",
      "197749      197749              Neon Jesus  planetpunk.crypto send ü™ô   \n",
      "197750      197750    LimeWireCrypto {LWC}                    Crypto   \n",
      "197751      197751              SLVBULLNOW             United States   \n",
      "197752      197752              Neon Jesus  planetpunk.crypto send ü™ô   \n",
      "\n",
      "                                         user_description      user_created  \\\n",
      "0       Non-Binaryüè≥Ô∏è‚ÄçüåàMetaverse Builder. Web3 Content ...  19/01/2021 10:54   \n",
      "1       Making #Bitcoin more than an investment @spira...  16/01/2012 20:55   \n",
      "2       I am NOT a financial advisor. I AM a cryptocur...   21/03/2021 1:27   \n",
      "3       üé• YouTube: Crypto Rover with daily technical a...  24/01/2021 16:50   \n",
      "4       PSB Advanced Technology, LLC CTO \"Bridge the G...  24/04/2020 20:05   \n",
      "...                                                   ...               ...   \n",
      "197748  üíØüíØüíØ follow backüíØüíØüíØüíØüíØ üíØüíØüíØüíØüíØüíØ‚ù£Ô∏è‚ù£Ô∏è‚ù£Ô∏èü•Äü•Äü•Äfollow bac...   7/05/2021 13:37   \n",
      "197749  Project House for Neon Jesus. Follow here for ...   5/11/2021 18:40   \n",
      "197750                                          LWC, KA$H   13/03/2022 8:00   \n",
      "197751  Full armour on.\\nTime is now to live a  Health...   1/12/2016 18:46   \n",
      "197752  Project House for Neon Jesus. Follow here for ...   5/11/2021 18:40   \n",
      "\n",
      "        user_followers  user_friends  user_favourites  user_verified  \\\n",
      "0                 4082           221            59613          False   \n",
      "1                 3771           439            11363          False   \n",
      "2                   19           109              132          False   \n",
      "3                53920           241            13165          False   \n",
      "4                 1443          2420            10527          False   \n",
      "...                ...           ...              ...            ...   \n",
      "197748           20888         22001             3500           True   \n",
      "197749              96           400             2439           True   \n",
      "197750               7            31               68           True   \n",
      "197751              95            61              635           True   \n",
      "197752              96           400             2439           True   \n",
      "\n",
      "                      date                                               text  \\\n",
      "0      2022-11-01 17:11:00  Another decent bounce for #Bitcoin $BTC\\n\\n1w,...   \n",
      "1      2022-11-01 17:11:00  Heads up! I'll be going live this Thursday at ...   \n",
      "2      2022-11-01 17:11:00  Not too much, but 2022 be good to me baby! Bin...   \n",
      "3      2022-11-01 17:11:00      #BITCOIN HERE WE GO!! https://t.co/9HgSsh1qsD   \n",
      "4      2022-11-01 17:11:00  https://t.co/KUBQR8cz2k FutureSELF Collection ...   \n",
      "...                    ...                                                ...   \n",
      "197748 2022-03-19 23:59:00  @TelefyConnect #DeFi #TeleFy #DEX #cryptocurre...   \n",
      "197749 2022-03-19 23:59:00  @nftdreami https://t.co/bODkhxCVE6\\n\\nOnly .06...   \n",
      "197750 2022-03-19 23:59:00  So what i‚Äôm seeing and hearing from #Ethereum ...   \n",
      "197751 2022-03-19 23:59:00  @mike_maloney @saylor Without the intricacies ...   \n",
      "197752 2022-03-19 23:59:00  @Whiteirons112 https://t.co/bODkhxCVE6\\n\\nOnly...   \n",
      "\n",
      "                                                 hashtags  \\\n",
      "0                                     ['bitcoin', 'hodl']   \n",
      "1                                             ['bitcoin']   \n",
      "2                          ['nft', 'ethereum', 'bitcoin']   \n",
      "3                                             ['bitcoin']   \n",
      "4       ['iot', 'crypto', 'fashion', 'shirts', 'future...   \n",
      "...                                                   ...   \n",
      "197748  ['defi', 'telefy', 'dex', 'cryptocurrency', 'e...   \n",
      "197749  ['crypto', 'planetpunk', 'nftgiveway', 'freenf...   \n",
      "197750         ['ethereum', 'btc', 'altcoin', 'altcoins']   \n",
      "197751                      ['gold', 'silver', 'bitcoin']   \n",
      "197752  ['crypto', 'planetpunk', 'nftgiveway', 'freenf...   \n",
      "\n",
      "               tweet_source  user_days_on_twitter RiseFall  \n",
      "0       Twitter for Android                   357    Equal  \n",
      "1           Twitter Web App                  3647    Equal  \n",
      "2       Twitter for Android                   296    Equal  \n",
      "3           Twitter Web App                   352    Equal  \n",
      "4           Twitter Web App                   626    Equal  \n",
      "...                     ...                   ...      ...  \n",
      "197748  Twitter for Android                   316     Fall  \n",
      "197749      Twitter Web App                   134     Fall  \n",
      "197750   Twitter for iPhone                     6     Fall  \n",
      "197751  Twitter for Android                  1934     Fall  \n",
      "197752      Twitter Web App                   134     Fall  \n",
      "\n",
      "[197748 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'hashtags' column to lowercase to perform a case-insensitive search\n",
    "df['hashtags'] = df['hashtags'].str.lower()\n",
    "\n",
    "# Define a list of keywords you want to search for\n",
    "keywords = ['btc', 'bitcoin']\n",
    "\n",
    "# Create a regex pattern to match any of the specified keywords\n",
    "pattern = '|'.join(keywords)\n",
    "\n",
    "# Use str.contains() to filter rows with the specified keywords in hashtags\n",
    "filtered_df = df[df['hashtags'].str.contains(pattern, case=False, na=False)]\n",
    "\n",
    "# Print the filtered DataFrame\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a365cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 197748 entries, 0 to 197752\n",
      "Data columns (total 15 columns):\n",
      " #   Column                Non-Null Count   Dtype         \n",
      "---  ------                --------------   -----         \n",
      " 0   Unnamed: 0            197748 non-null  int64         \n",
      " 1   user_name             197748 non-null  object        \n",
      " 2   user_location         197748 non-null  object        \n",
      " 3   user_description      197748 non-null  object        \n",
      " 4   user_created          197748 non-null  object        \n",
      " 5   user_followers        197748 non-null  int64         \n",
      " 6   user_friends          197748 non-null  int64         \n",
      " 7   user_favourites       197748 non-null  int64         \n",
      " 8   user_verified         197748 non-null  bool          \n",
      " 9   date                  197748 non-null  datetime64[ns]\n",
      " 10  text                  197748 non-null  object        \n",
      " 11  hashtags              197748 non-null  object        \n",
      " 12  tweet_source          197748 non-null  object        \n",
      " 13  user_days_on_twitter  197748 non-null  int64         \n",
      " 14  RiseFall              197748 non-null  object        \n",
      "dtypes: bool(1), datetime64[ns](1), int64(5), object(8)\n",
      "memory usage: 22.8+ MB\n"
     ]
    }
   ],
   "source": [
    "filtered_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5592b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jd/4dt6h54973j7mc7x_q5d4cwh0000gn/T/ipykernel_18011/3094204154.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=['RiseFall'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "filtered_df.drop(columns=['RiseFall'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "428a4203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 197748 entries, 0 to 197752\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count   Dtype         \n",
      "---  ------                --------------   -----         \n",
      " 0   Unnamed: 0            197748 non-null  int64         \n",
      " 1   user_name             197748 non-null  object        \n",
      " 2   user_location         197748 non-null  object        \n",
      " 3   user_description      197748 non-null  object        \n",
      " 4   user_created          197748 non-null  object        \n",
      " 5   user_followers        197748 non-null  int64         \n",
      " 6   user_friends          197748 non-null  int64         \n",
      " 7   user_favourites       197748 non-null  int64         \n",
      " 8   user_verified         197748 non-null  bool          \n",
      " 9   date                  197748 non-null  datetime64[ns]\n",
      " 10  text                  197748 non-null  object        \n",
      " 11  hashtags              197748 non-null  object        \n",
      " 12  tweet_source          197748 non-null  object        \n",
      " 13  user_days_on_twitter  197748 non-null  int64         \n",
      "dtypes: bool(1), datetime64[ns](1), int64(5), object(7)\n",
      "memory usage: 21.3+ MB\n"
     ]
    }
   ],
   "source": [
    "filtered_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37af2539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jd/4dt6h54973j7mc7x_q5d4cwh0000gn/T/ipykernel_18011/189528385.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=['Unnamed: 0', 'user_name', 'user_description', 'user_followers', 'user_favourites','user_location', 'user_created', 'user_friends', 'user_verified', 'user_days_on_twitter'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "filtered_df.drop(columns=['Unnamed: 0', 'user_name', 'user_description', 'user_followers', 'user_favourites','user_location', 'user_created', 'user_friends', 'user_verified', 'user_days_on_twitter'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a93c4343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 197748 entries, 0 to 197752\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count   Dtype         \n",
      "---  ------        --------------   -----         \n",
      " 0   date          197748 non-null  datetime64[ns]\n",
      " 1   text          197748 non-null  object        \n",
      " 2   hashtags      197748 non-null  object        \n",
      " 3   tweet_source  197748 non-null  object        \n",
      "dtypes: datetime64[ns](1), object(3)\n",
      "memory usage: 7.5+ MB\n"
     ]
    }
   ],
   "source": [
    "filtered_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d4becbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/aishu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/aishu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/aishu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "/var/folders/jd/4dt6h54973j7mc7x_q5d4cwh0000gn/T/ipykernel_18011/363384559.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['processed_text'] = filtered_df['text'].apply(process_text)\n",
      "/var/folders/jd/4dt6h54973j7mc7x_q5d4cwh0000gn/T/ipykernel_18011/363384559.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['vader_sentiment'] = filtered_df['processed_text'].apply(get_sentiment_vader)\n",
      "/var/folders/jd/4dt6h54973j7mc7x_q5d4cwh0000gn/T/ipykernel_18011/363384559.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['textblob_sentiment'] = filtered_df['processed_text'].apply(get_sentiment_textblob)\n",
      "/var/folders/jd/4dt6h54973j7mc7x_q5d4cwh0000gn/T/ipykernel_18011/363384559.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['vader_sentiment_class'] = filtered_df['vader_sentiment'].apply(classify_sentiment_vader)\n",
      "/var/folders/jd/4dt6h54973j7mc7x_q5d4cwh0000gn/T/ipykernel_18011/363384559.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['textblob_sentiment_class'] = filtered_df['textblob_sentiment'].apply(classify_sentiment_textblob)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize the lemmatizer and get a set of stop words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Initialize the VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to process text\n",
    "def process_text(text):\n",
    "    # Remove special characters using regular expressions\n",
    "    text = re.sub(r'[^A-Za-z0-9]+', ' ', text)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Remove stop words and lemmatize the remaining words\n",
    "    filtered_words = [lemmatizer.lemmatize(word) for word in words if word.lower() not in stop_words]\n",
    "\n",
    "    # Reconstruct the text from the processed words\n",
    "    processed_text = ' '.join(filtered_words)\n",
    "\n",
    "    return processed_text\n",
    "\n",
    "# Apply text processing to the 'text' column\n",
    "filtered_df['processed_text'] = filtered_df['text'].apply(process_text)\n",
    "\n",
    "# Function to get sentiment using VADER\n",
    "def get_sentiment_vader(text):\n",
    "    sentiment = analyzer.polarity_scores(text)\n",
    "    return sentiment['compound']\n",
    "\n",
    "# Function to get sentiment using TextBlob\n",
    "def get_sentiment_textblob(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "# Apply sentiment analysis using VADER\n",
    "filtered_df['vader_sentiment'] = filtered_df['processed_text'].apply(get_sentiment_vader)\n",
    "\n",
    "# Apply sentiment analysis using TextBlob\n",
    "filtered_df['textblob_sentiment'] = filtered_df['processed_text'].apply(get_sentiment_textblob)\n",
    "\n",
    "# Classify sentiment based on compound VADER score\n",
    "def classify_sentiment_vader(compound):\n",
    "    if compound >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif compound <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Classify sentiment based on TextBlob score\n",
    "def classify_sentiment_textblob(score):\n",
    "    if score >= 0.1:\n",
    "        return 'Positive'\n",
    "    elif score <= -0.1:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Apply sentiment classification\n",
    "filtered_df['vader_sentiment_class'] = filtered_df['vader_sentiment'].apply(classify_sentiment_vader)\n",
    "filtered_df['textblob_sentiment_class'] = filtered_df['textblob_sentiment'].apply(classify_sentiment_textblob)\n",
    "\n",
    "# Save the DataFrame with sentiment analysis results\n",
    "filtered_df.to_csv('BTC_final_tweet_sentiments_combined.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f70322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45111aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
